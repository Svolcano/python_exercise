import ujson
import pathlib
import csv

# 陌电词典
class MoDianConst(object):
    md_province = ["北京", "天津", "河北", "山西", "内蒙古", "辽宁",
                        "吉林", "黑龙江", "上海", "江苏", "浙江", "安徽",
                        "福建", "江西", "山东", "河南", "湖北", "湖南",
                        "广东", "广西", "海南", "重庆", "四川", "贵州",
                        "云南", "西藏", "陕西", "甘肃", "青海", "宁夏",
                        "新疆", "香港", "澳门", "台湾"]
    md_city = [
    "上海", "北京", "广州", "武汉", "天津", "重庆", "南京", "成都", "沈阳",
    "杭州", "深圳", "西安", "长春", "苏州", "济南", "无锡", "青岛", "厦门",
    "大连", "郑州", "福州", "哈尔滨", "宁波", "石家庄", "东莞", "佛山", "长沙",
    "昆明", "合肥", "太原", "南昌", "贵阳", "常州", "珠海", "南宁", "扬州", "兰州",
    "温州", "南通", "海口", "乌鲁木齐", "呼和浩特", "嘉兴", "西宁", "绍兴", "丽江",
    "三亚", "桂林", "镇江", "徐州", "汕头", "烟台", "秦皇岛", "保定", "洛阳", "泉州",
    "中山", "银川", "潍坊", "威海", "金华", "廊坊", "江门", "舟山", "台州", "邢台",
    "惠州", "邯郸", "绵阳", "唐山", "连云港", "湖州", "拉萨", "赣州", "新乡", "阳江",
    "淄博", "黄山", "泰安", "大理", "临沂", "乐山", "德州", "鞍山", "济宁", "吉林",
    "肇庆", "泰州", "淮安", "宜昌", "盐城", "茂名", "大庆", "大同", "东营", "自贡",
    "宝鸡", "韶关", "九江", "沧州", "咸阳", "德阳", "包头", "张家界", "日照", "南充",
    "湛江", "芜湖", "锦州", "清远", "南阳", "许昌", "西双版纳", "开封", "抚顺",
    "葫芦岛", "柳州", "蚌埠", "上饶", "荆州", "聊城", "达州", "湘西", "承德",
    "梅州", "宜宾", "丹东", "宜春", "营口", "三明", "凉山", "巴音郭楞",
    "张家口", "安庆", "牡丹江", "枣庄", "宁德", "衡阳", "株洲",
    "滨州", "龙岩", "遂宁", "安阳", "齐齐哈尔", "焦作", "襄阳", "吉安",
    "吕梁", "黄冈", "马鞍山", "阿坝", "北海", "雅安", "滁州", "广安", "攀枝花",
    "信阳", "衢州", "盘锦", "泸州", "淮南", "内江", "红河", "莆田", "宿州", "十堰",
    "呼伦贝尔", "渭南", "黄石", "湘潭", "漳州", "白城", "迪庆", "梧州", "平顶山", "眉山",
    "赤峰", "河源", "岳阳", "本溪", "辽阳", "宣城", "遵义", "汉中", "广元", "常德", "菏泽",
    "临汾", "南平", "鄂尔多斯", "六安", "延边", "阜阳", "晋中", "揭阳", "佳木斯", "丽水",
    "延安", "保山", "商丘", "运城", "长治", "衡水", "玉溪", "阳泉", "巴中", "资阳", "潮州",
    "贺州", "郴州", "邵阳", "鸡西", "甘孜", "酒泉", "濮阳", "荆门", "榆林", "淮北", "宿迁",
    "益阳", "景德镇", "周口", "通化", "黔东南", "德宏", "黑河", "阜新", "铁岭", "恩施", "巢湖",
    "驻马店", "孝感", "三门峡", "松原", "汕尾", "四平", "楚雄", "池州", "贵港", "玉林", "喀什",
    "怀化", "云浮", "昭通", "咸宁", "曲靖", "抚州", "林芝", "铜陵", "安康", "安顺", "新余",
    "朝阳", "伊犁", "随州", "琼海", "百色", "萍乡", "漯河", "莱芜", "亳州", "晋城", "钦州",
    "克拉玛依", "张掖", "忻州", "天水", "阿勒泰", "白山", "通辽", "永州", "石河子",
    "石嘴山", "娄底", "河池", "儋州", "防城港", "昌吉", "鹰潭", "哈密", "六盘水",
    "辽源", "万宁", "文山", "日喀则", "鹤壁", "嘉峪关", "庆阳", "朔州", "巴彦淖尔",
    "锡林郭勒", "大兴安岭", "乌兰察布", "乌海", "文昌", "黔西南", "潜江", "黔南",
    "武威", "吐鲁番", "伊春", "阿克苏", "铜仁", "兴安盟", "鄂州", "绥化", "怒江",
    "海西", "平凉", "铜川", "甘南", "商洛", "崇左", "临沧", "白银", "中卫", "塔城",
    "吴忠", "鹤岗", "济源", "七台河", "临夏", "东方", "和田", "双鸭山", "普洱", "来宾",
    "陵水", "陇南", "保亭", "阿里", "天门", "海东", "博尔塔拉", "澄迈县", "山南", "仙桃",
    "毕节", "五指山", "定西", "金昌", "海北", "阿拉善", "定安县", "固原", "那曲", "果洛",
    "神农架林区", "玉树", "昌江", "昌都", "乐东", "五家渠", "黄南", "琼中", "临高县",
    "屯昌县", "阿拉尔", "克孜勒苏", "海南", "白沙", "图木舒克", "三沙", "海拉尔",
    "思茅", "黔江", "都匀", "江汉", "库尔勒", "奎屯", "吉首", "涪陵", "格尔木",
    "共和", "万州", "海晏", "凯里", "西昌", "克州", "延吉", "博乐", "德令哈",
    "梅河口", "商州", "珲春", "潢川", "集宁", "临河", "贵池", "马尔康",
    "博州", "阿图什", "景洪", "乌兰浩特", "巴彦浩特"]
    md_provider = [
    "移动", "联通", "电信", "虚拟运营商", "阿里通信", "三五互联",
    "世纪互联", "中兴视通", "中期移动", "中麦通信", "乐语妙more",
    "京东通信", "分享通信", "华翔联信", "国美极信", "天音移动",
    "巴士在线", "普泰移动", "朗玛信息", "爱施德", "苏宁互联",
    "蜗牛移动", "话机通信", "远特信时空", "迪信通", "银盛",
    "长江时代", "鹏博士", "北京青牛", "二六三", "凤凰资产", "富士康",
    "广州博元", "海尔", "海航", "海信", "合一信息", "恒大和",
    "红豆集团", "连连", "联想", "民生电子", "平安通信", "小米",
    "星美", "用友", "中邮世纪"
    ]

# 行业一致性词典
class HYSimilarity(object):
    hy_dict = {
    }

    @classmethod
    def load_dict(cls):
        try:
            resource_path = pathlib.Path(__file__).parents[1] / "data" / "hangyedict"
            with open(resource_path, 'r', encoding='utf8') as fh:
                all = fh.read()
            cls.hy_dict = ujson.loads(all)
        except Exception as e:
            cls.hy_dict = {}


def we_load_dict():
    try:
        data_path = pathlib.Path(__file__).parents[1] / "data" / "dictionary"
        key_set = set()
        company_suffix = set()
        with open(data_path, encoding='utf8') as fh:
            for line in fh:
                vv = line.split(' ')
                k = vv[0].strip()
                t = vv[2].strip()
                if t == 'x':
                    continue
                else:
                    key_set.add(k)
                    if t == 'type':
                        company_suffix.add(k)
    except Exception as e:
        print("++webengine load dict except: ", e)
    return key_set, company_suffix


def load_ap():
    try:
        data_path = pathlib.Path(__file__).parents[1] / "data" / "area_p.dict"
        ret = {}
        with open(data_path, encoding='utf8') as fh:
            cr = csv.reader(fh)
            for line in cr:
                a = line[0].strip()
                p = line[1].strip()
                pp = line[2].strip()
                ret[f'0{a}'] = (p, pp)

    except Exception as e:
        print("++webengine load dict except: ", e)
    return ret

if __name__ == "__main__":
    for k, v in HYSimilarity.hy_dict.items():
        print(k,type(v))